import httpx
import asyncio
import json
import os
import re
from typing import Dict, Any, List, AsyncGenerator
from models import Agent, MCPServer
from utils import logger, format_openai_messages

# MCP imports
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
# ä¼˜å…ˆå¯¼å…¥ Streamable HTTP å®¢æˆ·ç«¯ï¼ˆHTTP ä¼ è¾“æ¨èï¼‰
try:
    from mcp.client.streamable_http import streamablehttp_client as http_stream_client  # type: ignore
except Exception:
    http_stream_client = None
# å…¼å®¹ï¼šSSE å®¢æˆ·ç«¯ï¼ˆä¸æ¨èï¼Œä¿åº•ï¼‰
try:
    from mcp.client.sse import sse_client  # type: ignore
except Exception:
    sse_client = None

import mcp.types as mcp_types


class OpenAIHandler:
    """OpenAI API å¤„ç†å™¨"""

    def __init__(self):
        # ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤çš„ OpenAI å…¼å®¹æ¥å£
        self.base_url = os.getenv("OPENAI_BASE_URL", "http://192.168.31.159:8088/api/v1/gpt/v1")
        self.api_key = os.getenv("OPENAI_API_KEY", "dummy-key")

        self.client = httpx.AsyncClient(
            timeout=120,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
        )

    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "qwen3:32b",
        max_tokens: int = None,
        stream: bool = False
    ) -> Dict[str, Any]:
        """è°ƒç”¨ OpenAI Chat Completion API"""
        try:
            payload = {
                "model": model,
                "messages": messages,
                "stream": stream
            }

            if max_tokens:
                payload["max_tokens"] = max_tokens

            response = await self.client.post(
                f"{self.base_url}/chat/completions",
                json=payload
            )

            if response.status_code != 200:
                raise Exception(f"API è¯·æ±‚å¤±è´¥: {response.status_code} {response.text}")

            data = response.json()

            if stream:
                return data
            else:
                # å¤„ç†æ ‡å‡† OpenAI æ ¼å¼
                if "choices" in data and data["choices"]:
                    choice = data["choices"][0]
                    message = choice.get("message", {})
                    return {
                        "content": message.get("content", ""),
                        "role": message.get("role", "assistant"),
                        "usage": data.get("usage", {"total_tokens": 50})
                    }
                else:
                    return {
                        "content": str(data),
                        "role": "assistant",
                        "usage": {"total_tokens": 50}
                    }
        except Exception as e:
            logger.error(f"OpenAI API è°ƒç”¨å¤±è´¥: {str(e)}")
            # è¿”å›æ¨¡æ‹Ÿå“åº”ï¼Œé¿å…å› å¤–éƒ¨æœåŠ¡ä¸å¯ç”¨å¯¼è‡´æ•´ä¸ªç³»ç»Ÿæ— æ³•ä½¿ç”¨
            return {
                "content": f"API è°ƒç”¨å¤±è´¥",
                "role": "assistant",
                "usage": {"total_tokens": 50}
            }

    async def chat_completion_stream(
        self,
        messages: List[Dict[str, str]],
        model: str = "qwen3:32b",
        max_tokens: int = None
    ) -> AsyncGenerator[str, None]:
        """æµå¼è°ƒç”¨ OpenAI Chat Completion API"""
        try:
            payload = {
                "model": model,
                "messages": messages,
                "stream": True
            }

            if max_tokens:
                payload["max_tokens"] = max_tokens

            async with self.client.stream(
                "POST",
                f"{self.base_url}/chat/completions",
                json=payload
            ) as response:
                if response.status_code != 200:
                    raise Exception(f"API è¯·æ±‚å¤±è´¥: {response.status_code}")

                async for line in response.aiter_lines():
                    if not line.strip():
                        continue

                    if line.startswith("data: "):
                        data_str = line[6:]  # å»æ‰ "data: " å‰ç¼€

                        if data_str.strip() == "[DONE]":
                            break

                        try:
                            chunk_data = json.loads(data_str)
                            choices = chunk_data.get("choices", [])
                            if choices:
                                delta = choices[0].get("delta", {})
                                content = delta.get("content", "")
                                if content:
                                    yield content
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯ JSONï¼Œè·³è¿‡è¿™è¡Œ
                            continue

        except Exception as e:
            logger.error(f"OpenAI API æµå¼è°ƒç”¨å¤±è´¥: {str(e)}")
            # è¿”å›æ¨¡æ‹Ÿçš„æµå¼å“åº”
            mock_response = f"API è°ƒç”¨å¤±è´¥"
            for char in mock_response:
                yield char

    async def chat_completion_with_tools(
        self,
        messages: List[Dict[str, str]],
        tools: List[Dict[str, Any]],
        model: str = "qwen3:32b",
        max_tokens: int = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ OpenAI Chat Completion API å¹¶æ”¯æŒå·¥å…·è°ƒç”¨"""
        try:
            payload = {
                "model": model,
                "messages": messages,
                "tools": tools,
                "tool_choice": "auto"
            }

            if max_tokens:
                payload["max_tokens"] = max_tokens

            response = await self.client.post(
                f"{self.base_url}/chat/completions",
                json=payload
            )

            if response.status_code != 200:
                raise Exception(f"API è¯·æ±‚å¤±è´¥: {response.status_code} {response.text}")

            # å®‰å…¨è§£æå“åº”
            try:
                data = response.json()
            except Exception as json_error:
                logger.error(f"JSON è§£æå¤±è´¥: {json_error}, åŸå§‹å“åº”: {response.text[:500]}")
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
                return self._parse_non_json_response(response.text, messages)

            # å¤„ç†æ ‡å‡† OpenAI æ ¼å¼
            if "choices" in data and data["choices"]:
                choice = data["choices"][0]
                message = choice.get("message", {})
                result = {
                    "content": message.get("content", ""),
                    "role": message.get("role", "assistant"),
                    "usage": data.get("usage", {"total_tokens": 50})
                }

                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if "tool_calls" in message and message["tool_calls"]:
                    result["tool_calls"] = message["tool_calls"]

                return result
            else:
                # éæ ‡å‡†æ ¼å¼ï¼Œå°è¯•è§£æ
                return self._parse_alternative_format(data, messages)

        except Exception as e:
            logger.error(f"OpenAI API å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
            # è¿”å›æ¨¡æ‹Ÿå“åº”ï¼Œé¿å…å› å¤–éƒ¨æœåŠ¡ä¸å¯ç”¨å¯¼è‡´æ•´ä¸ªç³»ç»Ÿæ— æ³•ä½¿ç”¨
            return {
                "content": f"æ¨¡æ‹ŸAIå›å¤ï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰ï¼š{messages[-1]['content'] if messages else 'ä½ å¥½'}",
                "role": "assistant",
                "usage": {"total_tokens": 50}
            }

    def _parse_non_json_response(self, text: str, messages: List[Dict[str, str]]) -> Dict[str, Any]:
        """è§£æé JSON æ ¼å¼çš„å“åº”ï¼Œå°è¯•æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        import re

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´ç›¸å…³çš„å…³é”®è¯ï¼Œå¦‚æœæœ‰åˆ™ç”Ÿæˆå·¥å…·è°ƒç”¨
        time_keywords = ["æ—¶é—´", "å‡ ç‚¹", "ç°åœ¨", "å½“å‰æ—¶é—´", "time", "clock"]
        user_message = messages[-1].get("content", "").lower() if messages else ""

        should_call_time_tool = any(keyword in user_message for keyword in time_keywords)

        tool_calls = []
        content = text

        if should_call_time_tool and "æ— æ³•" not in text and "ä¸èƒ½" not in text:
            # ç”Ÿæˆæ—¶é—´å·¥å…·è°ƒç”¨
            tool_calls.append({
                "id": "call_time_1",
                "type": "function",
                "function": {
                    "name": "time_http_get_current_time",
                    "arguments": "{}"
                }
            })

            # ä¿®æ”¹å†…å®¹ï¼Œè¡¨ç¤ºæ­£åœ¨è°ƒç”¨å·¥å…·
            content = "æˆ‘æ¥ä¸ºæ‚¨æŸ¥è¯¢å½“å‰æ—¶é—´ã€‚"

        result = {
            "content": content,
            "role": "assistant",
            "usage": {"total_tokens": 50}
        }

        if tool_calls:
            result["tool_calls"] = tool_calls

        return result

    def _parse_alternative_format(self, data: Dict[str, Any], messages: List[Dict[str, str]]) -> Dict[str, Any]:
        """è§£æéæ ‡å‡†æ ¼å¼çš„ JSON å“åº”"""
        # å°è¯•ä¸åŒçš„å“åº”æ ¼å¼
        content = ""
        tool_calls = []

        # æ ¼å¼1ï¼šç›´æ¥åœ¨æ ¹çº§åˆ«æœ‰ content
        if "content" in data:
            content = str(data["content"])
        elif "text" in data:
            content = str(data["text"])
        elif "response" in data:
            content = str(data["response"])
        else:
            content = str(data)

        # æ ¼å¼2ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨å­—æ®µ
        for key in ["tool_calls", "tools", "function_calls", "functions"]:
            if key in data and data[key]:
                try:
                    raw_calls = data[key]
                    if isinstance(raw_calls, list):
                        for i, call in enumerate(raw_calls):
                            if isinstance(call, dict):
                                # æ ‡å‡†åŒ–å·¥å…·è°ƒç”¨æ ¼å¼
                                tool_call = {
                                    "id": call.get("id", f"call_{i}"),
                                    "type": "function",
                                    "function": {
                                        "name": call.get("name", call.get("function", {}).get("name", "")),
                                        "arguments": json.dumps(call.get("arguments", call.get("parameters", {})))
                                    }
                                }
                                tool_calls.append(tool_call)
                except Exception as e:
                    logger.error(f"è§£æå·¥å…·è°ƒç”¨å¤±è´¥: {e}")

        result = {
            "content": content,
            "role": "assistant",
            "usage": {"total_tokens": 50}
        }

        if tool_calls:
            result["tool_calls"] = tool_calls

        return result


class MCPClientHandler:
    """MCP å®¢æˆ·ç«¯å¤„ç†å™¨ - è¿æ¥åˆ°å¤–éƒ¨ MCP æœåŠ¡å™¨"""

    def __init__(self):
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        # è¿è¡ŒæœŸä»æ•°æ®åº“åŠ¨æ€åŠ è½½æœåŠ¡å™¨é…ç½®
        self.mcp_servers: Dict[str, Dict[str, Any]] = {}

    async def load_servers(self) -> None:
        """ä»æ•°æ®åº“åŠ¨æ€åŠ è½½ MCP æœåŠ¡å™¨é…ç½®åˆ°å†…å­˜æ˜ å°„"""
        try:
            servers = await MCPServer.all()
            mapping: Dict[str, Dict[str, Any]] = {}
            for s in servers:
                url = (s.api_url or '').strip()
                # ä»…æ”¯æŒ http(s) åè®®
                if url.startswith("http://") or url.startswith("https://"):
                    mapping[s.name] = {
                        "transport": "http" if http_stream_client is not None else "sse",
                        "url": url,
                        "description": s.description,
                    }
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„ MCP api_url åè®®: {url}")
            self.mcp_servers = mapping
        except Exception as e:
            logger.error(f"åŠ è½½ MCP æœåŠ¡å™¨é…ç½®å¤±è´¥: {str(e)}")

    async def call_mcp_tool(
        self,
        server_name: str,
        tool_name: str,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è°ƒç”¨ MCP æœåŠ¡å™¨ä¸Šçš„å·¥å…·"""
        try:
            # ç¡®ä¿æœåŠ¡å™¨é…ç½®æ˜¯æœ€æ–°çš„
            await self.load_servers()
            if server_name not in self.mcp_servers:
                return {
                    "success": False,
                    "error": f"MCP æœåŠ¡å™¨ {server_name} ä¸å­˜åœ¨"
                }

            server_config = self.mcp_servers[server_name]

            # æ ¹æ® transport è¿æ¥æœåŠ¡å™¨ï¼ˆSSE æˆ– stdioï¼‰
            if server_config.get("transport") == "http":
                if http_stream_client is None:
                    return {"success": False, "error": "åç«¯æœªå®‰è£…æ”¯æŒ HTTP MCP çš„ http å®¢æˆ·ç«¯ï¼Œè¯·å‡çº§ mcp åŒ…"}
                async with http_stream_client(server_config["url"]) as (read, write, _get_sid):  # type: ignore
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        result = await session.call_tool(tool_name, arguments=parameters)
            elif server_config.get("transport") == "sse":
                if sse_client is None:
                    return {"success": False, "error": "åç«¯æœªå®‰è£…æ”¯æŒ HTTP(S) MCP çš„ sse å®¢æˆ·ç«¯ï¼Œè¯·å‡çº§ mcp åŒ…æˆ–æ”¹ç”¨ stdio æœåŠ¡å™¨"}
                async with sse_client(server_config["url"]) as (read, write):  # type: ignore
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        result = await session.call_tool(tool_name, arguments=parameters)
            else:
                server_params = StdioServerParameters(command=server_config["command"], args=server_config["args"])
                async with stdio_client(server_params) as (read, write):
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        result = await session.call_tool(tool_name, arguments=parameters)

                    # å¤„ç†ç»“æœ
                    if result.isError:
                        error_content = ""
                        for content in result.content:
                            if isinstance(content, mcp_types.TextContent):
                                error_content += content.text
                        return {
                            "success": False,
                            "error": f"MCP å·¥å…·æ‰§è¡Œå¤±è´¥: {error_content}"
                        }
                    else:
                        # æå–ç»“æœå†…å®¹
                        result_content = ""
                        for content in result.content:
                            if isinstance(content, mcp_types.TextContent):
                                result_content += content.text

                        return {
                            "success": True,
                            "result": result_content
                        }

        except Exception as e:
            logger.error(f"MCP æœåŠ¡å™¨è°ƒç”¨å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    async def get_available_tools(self) -> List[Dict[str, Any]]:
        """èšåˆæ‰€æœ‰æ´»åŠ¨ MCP æœåŠ¡å™¨çš„å·¥å…·ï¼ˆåŠ¨æ€ï¼‰"""
        # ç¡®ä¿åŠ è½½æœ€æ–°æœåŠ¡å™¨åˆ—è¡¨
        await self.load_servers()
        tools: List[Dict[str, Any]] = []
        for server_name in self.mcp_servers.keys():
            # åŠ¨æ€æŸ¥è¯¢æ¯ä¸ªæœåŠ¡å™¨å¯ç”¨å·¥å…·
            dynamic_tools = await self.get_server_tools_dynamic(server_name)
            for t in dynamic_tools:
                tools.append({
                    "type": "function",
                    "function": {
                        "name": f"{server_name}_{t['name']}",
                        "description": f"{t.get('description', '')}",
                        "parameters": t.get('parameters', {}) or {}
                    }
                })
        return tools

    def get_mcp_servers_info(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ MCP æœåŠ¡å™¨ä¿¡æ¯"""
        servers_info = {}
        for server_name, server_config in self.mcp_servers.items():
            servers_info[server_name] = {
                "name": server_name,
                "description": server_config["description"],
                "tools": server_config.get("tools", []),
                "command": server_config["command"],
                "args": server_config["args"]
            }
        return servers_info

    async def get_server_tools_dynamic(self, server_name: str) -> List[Dict[str, Any]]:
        """åŠ¨æ€è·å– MCP æœåŠ¡å™¨çš„å·¥å…·åˆ—è¡¨"""
        try:
            # ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æœåŠ¡å™¨æ˜ å°„
            await self.load_servers()
            if server_name not in self.mcp_servers:
                return []

            server_config = self.mcp_servers[server_name]

            # æ ¹æ®ä¼ è¾“æ–¹å¼è¿æ¥åˆ° MCP æœåŠ¡å™¨è·å–å·¥å…·åˆ—è¡¨
            if server_config.get("transport") == "http" and http_stream_client is not None:
                async with http_stream_client(server_config["url"]) as (read, write, _get_sid):  # type: ignore
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        tools_response = await session.list_tools()
            elif server_config.get("transport") == "sse" and sse_client is not None:
                async with sse_client(server_config["url"]) as (read, write):  # type: ignore
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        tools_response = await session.list_tools()
            else:
                server_params = StdioServerParameters(command=server_config["command"], args=server_config["args"])
                async with stdio_client(server_params) as (read, write):
                    async with ClientSession(read, write) as session:
                        await session.initialize()
                        tools_response = await session.list_tools()

            tools = []
            for tool in tools_response.tools:
                tools.append({
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema if hasattr(tool, 'inputSchema') else {}
                })

            return tools

        except Exception as e:
            logger.error(f"è·å– MCP æœåŠ¡å™¨ {server_name} å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}")
            # å¤±è´¥æ—¶è¿”å›ç©º
            return []


class AgentHandler:
    """Agent å¤„ç†å™¨ - ç®¡ç† Agent å¹¶ä¸ MCP æœåŠ¡å™¨äº¤äº’"""

    def __init__(self):
        self.openai_handler = OpenAIHandler()
        self.mcp_handler = MCPClientHandler()

    async def process_message(
        self,
        agent_id: int,
        messages: List[Dict[str, str]],
        stream: bool = False
    ) -> Dict[str, Any]:
        """å¤„ç†æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤ - æ”¯æŒ MCP å·¥å…·è°ƒç”¨"""
        try:
            agent = await Agent.get(id=agent_id)

            # æ ¼å¼åŒ–æ¶ˆæ¯
            formatted_messages = format_openai_messages(agent.prompt, messages)

            # è·å– OpenAI é…ç½®
            openai_config = agent.openai_config or {}
            model = openai_config.get("model", "qwen3:32b")
            max_tokens = openai_config.get("max_tokens")

            # æ£€æŸ¥ Agent æ˜¯å¦é…ç½®äº† MCP å·¥å…·
            agent_tools = agent.mcp_tools or []

            if agent_tools and not stream:  # å·¥å…·è°ƒç”¨æš‚ä¸æ”¯æŒæµå¼
                # è·å–å¯ç”¨å·¥å…·
                available_tools = await self.mcp_handler.get_available_tools()

                # è¿‡æ»¤ Agent é…ç½®çš„å·¥å…·
                filtered_tools = [
                    tool for tool in available_tools
                    if any(mcp_tool in tool["function"]["name"] for mcp_tool in agent_tools)
                ]

                if filtered_tools:
                    return await self._process_with_tools(
                        formatted_messages,
                        filtered_tools,
                        model,
                        max_tokens
                    )

            # æ²¡æœ‰å·¥å…·æˆ–ä½¿ç”¨æµå¼æ—¶ï¼Œç›´æ¥è°ƒç”¨ OpenAI
            if stream:
                return await self.openai_handler.chat_completion_stream(
                    messages=formatted_messages,
                    model=model,
                    max_tokens=max_tokens
                )
            else:
                return await self.openai_handler.chat_completion(
                    messages=formatted_messages,
                    model=model,
                    max_tokens=max_tokens
                )

        except Agent.DoesNotExist:
            return {
                "success": False,
                "error": "Agent ä¸å­˜åœ¨"
            }
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    async def process_message_stream(
        self,
        agent_id: int,
        messages: List[Dict[str, str]],
    ) -> AsyncGenerator[str, None]:
        """å¤„ç†æ¶ˆæ¯å¹¶ä»¥æµå¼æ–¹å¼è¿”å›å›å¤ï¼Œå…ˆè¿›è¡Œ MCP å·¥å…·è°ƒç”¨ï¼ˆå¦‚éœ€è¦ï¼‰ï¼Œå†æµå¼è¾“å‡ºæœ€ç»ˆå›å¤"""
        try:
            agent = await Agent.get(id=agent_id)

            # æ ¼å¼åŒ–æ¶ˆæ¯
            formatted_messages = format_openai_messages(agent.prompt, messages)

            # OpenAI é…ç½®
            openai_config = agent.openai_config or {}
            model = openai_config.get("model", "qwen3:32b")
            max_tokens = openai_config.get("max_tokens")

            agent_tools = agent.mcp_tools or []

            if agent_tools:
                available_tools = await self.mcp_handler.get_available_tools()
                filtered_tools = [
                    tool for tool in available_tools
                    if any(mcp_tool in tool["function"]["name"] for mcp_tool in agent_tools)
                ]
                if filtered_tools:
                    # è¾“å‡ºå·¥å…·å‡†å¤‡ä¿¡æ¯
                    yield f"<mcp>ğŸ”§ å‡†å¤‡è°ƒç”¨ MCP å·¥å…·ï¼š{', '.join([tool['function']['name'] for tool in filtered_tools])}</mcp>\n\n"

                    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œè·å–å·¥å…·è°ƒç”¨
                    first = await self.openai_handler.chat_completion_with_tools(
                        messages=formatted_messages,
                        tools=filtered_tools,
                        model=model,
                        max_tokens=max_tokens,
                    )
                    if first.get("tool_calls"):
                        yield f"<mcp>ğŸ¯ AI å†³å®šè°ƒç”¨ {len(first['tool_calls'])} ä¸ªå·¥å…·</mcp>\n\n"

                        # å°†å·¥å…·è°ƒç”¨ä¸ç»“æœåŠ å…¥æ¶ˆæ¯
                        messages_with_tools = list(formatted_messages)
                        messages_with_tools.append({
                            "role": "assistant",
                            "content": first.get("content") or "",
                            "tool_calls": first["tool_calls"],
                        })
                        for tool_call in first["tool_calls"]:
                            function_name = tool_call["function"]["name"]

                            # å®‰å…¨è§£æ JSON å‚æ•°
                            try:
                                args_str = tool_call["function"]["arguments"]
                                if args_str and args_str.strip():
                                    function_args = json.loads(args_str)
                                else:
                                    function_args = {}
                            except (json.JSONDecodeError, KeyError) as e:
                                logger.error(f"è§£æå·¥å…·å‚æ•°å¤±è´¥: {e}, åŸå§‹å‚æ•°: {tool_call.get('function', {}).get('arguments', 'N/A')}")
                                function_args = {}

                            # è¾“å‡ºå·¥å…·è°ƒç”¨è¯¦æƒ…
                            yield f"<mcp>ğŸ“ è°ƒç”¨å·¥å…·: {function_name}</mcp>\n"
                            yield f"<mcp>ğŸ“ å‚æ•°: {json.dumps(function_args, ensure_ascii=False)}</mcp>\n\n"

                            # è§£ææœåŠ¡å™¨åå’Œå·¥å…·å
                            if function_name.startswith("time_http_"):
                                server_name = "time_http"
                                tool_name = function_name[10:]  # ç§»é™¤ "time_http_" å‰ç¼€
                            elif "_" in function_name:
                                server_name, tool_name = function_name.split("_", 1)
                            else:
                                server_name = "time_http"  # é»˜è®¤ä½¿ç”¨ time_http æœåŠ¡å™¨
                                tool_name = function_name
                            tool_result = await self.mcp_handler.call_mcp_tool(
                                server_name, tool_name, function_args
                            )

                            # è¾“å‡ºå·¥å…·ç»“æœ
                            yield f"<mcp>âœ… å·¥å…·è¿”å›: {json.dumps(tool_result, ensure_ascii=False)}</mcp>\n\n"

                            messages_with_tools.append({
                                "role": "tool",
                                "tool_call_id": tool_call["id"],
                                "content": json.dumps(tool_result),
                            })
                        # è¾“å‡ºæœ€ç»ˆå›å¤æç¤º
                        yield f"<mcp>ğŸ¤– åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤...</mcp>\n\n"

                        # æœ€ç»ˆæµå¼è¾“å‡º
                        async for chunk in self.openai_handler.chat_completion_stream(
                            messages=messages_with_tools,
                            model=model,
                            max_tokens=max_tokens,
                        ):
                            yield chunk
                        return

            # æ— å·¥å…·æˆ–æ— å·¥å…·è°ƒç”¨ï¼Œç›´æ¥æµå¼è¾“å‡º
            async for chunk in self.openai_handler.chat_completion_stream(
                messages=formatted_messages,
                model=model,
                max_tokens=max_tokens,
            ):
                yield chunk
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            # å»æ‰å…œåº•çš„æ¨¡æ‹Ÿè¿”å›ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œä¾¿äºä¸Šå±‚æ•è·å¹¶è¿”å›çœŸå®é”™è¯¯
            raise

    async def _process_with_tools(
        self,
        messages: List[Dict[str, str]],
        tools: List[Dict[str, Any]],
        model: str,
        max_tokens: int
    ) -> Dict[str, Any]:
        """ä½¿ç”¨å·¥å…·å¤„ç†æ¶ˆæ¯"""
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ OpenAIï¼Œå¯èƒ½ä¼šè¿”å›å·¥å…·è°ƒç”¨
            response = await self.openai_handler.chat_completion_with_tools(
                messages=messages,
                tools=tools,
                model=model,
                max_tokens=max_tokens
            )

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response.get("tool_calls"):
                # å¤„ç†å·¥å…·è°ƒç”¨
                messages.append({
                    "role": "assistant",
                    "content": response.get("content") or "",
                    "tool_calls": response["tool_calls"]
                })

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in response["tool_calls"]:
                    function_name = tool_call["function"]["name"]

                    # å®‰å…¨è§£æ JSON å‚æ•°
                    try:
                        args_str = tool_call["function"]["arguments"]
                        if args_str and args_str.strip():
                            function_args = json.loads(args_str)
                        else:
                            function_args = {}
                    except (json.JSONDecodeError, KeyError) as e:
                        logger.error(f"è§£æå·¥å…·å‚æ•°å¤±è´¥: {e}, åŸå§‹å‚æ•°: {tool_call.get('function', {}).get('arguments', 'N/A')}")
                        function_args = {}

                    # è§£ææœåŠ¡å™¨åå’Œå·¥å…·å
                    if function_name.startswith("time_http_"):
                        server_name = "time_http"
                        tool_name = function_name[10:]  # ç§»é™¤ "time_http_" å‰ç¼€
                    elif "_" in function_name:
                        server_name, tool_name = function_name.split("_", 1)
                    else:
                        server_name = "time_http"  # é»˜è®¤ä½¿ç”¨ time_http æœåŠ¡å™¨
                        tool_name = function_name

                    # è°ƒç”¨ MCP å·¥å…·
                    tool_result = await self.mcp_handler.call_mcp_tool(
                        server_name, tool_name, function_args
                    )

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call["id"],
                        "content": json.dumps(tool_result)
                    })

                # å†æ¬¡è°ƒç”¨ OpenAI è·å–æœ€ç»ˆå›å¤
                final_response = await self.openai_handler.chat_completion(
                    messages=messages,
                    model=model,
                    max_tokens=max_tokens
                )

                return final_response
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å›å¤
                return response

        except Exception as e:
            logger.error(f"å·¥å…·å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    async def get_agent_info(self, agent_id: int) -> Dict[str, Any]:
        """è·å– Agent ä¿¡æ¯"""
        try:
            agent = await Agent.get(id=agent_id)
            return {
                "success": True,
                "agent": {
                    "id": agent.id,
                    "name": agent.name,
                    "description": agent.description,
                    "prompt": agent.prompt,
                    "mcp_tools": agent.mcp_tools,
                    "openai_config": agent.openai_config,
                    "created_at": agent.created_at.isoformat(),
                    "updated_at": agent.updated_at.isoformat()
                }
            }
        except Agent.DoesNotExist:
            return {
                "success": False,
                "error": "Agent ä¸å­˜åœ¨"
            }
        except Exception as e:
            logger.error(f"è·å– Agent ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

    async def list_agents(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ Agent åˆ—è¡¨"""
        try:
            agents = await Agent.all()
            return {
                "success": True,
                "agents": [
                    {
                        "id": agent.id,
                        "name": agent.name,
                        "description": agent.description,
                        "mcp_tools": agent.mcp_tools,
                        "created_at": agent.created_at.isoformat(),
                        "updated_at": agent.updated_at.isoformat()
                    }
                    for agent in agents
                ]
            }
        except Exception as e:
            logger.error(f"è·å– Agent åˆ—è¡¨å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
